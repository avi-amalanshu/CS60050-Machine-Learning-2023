{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUt8S-0yA-rS"
      },
      "source": [
        "# Seed Type Determination Rating usingSingle Linkage Agglomerative (Bottom-Up) Clustering Technique (STHC-AS)\n",
        "## Machine Learning Project #3 \n",
        "## Avi Amalanshu (20EC30063)\n",
        "We are going to perform k-means clustering on the ```seed.csv``` dataset for various k. The best value of k will be used for agglomerative single-linkage bottom-up clustering. We will compare the clusterings generated by the two methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-ipbaBEC8Jp"
      },
      "source": [
        "## Setting up some global parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaxyvrOR1673"
      },
      "outputs": [],
      "source": [
        "# Roll Number: 20EC30063\n",
        "# Project Code: STHC-AS\n",
        "# Project Title: Seed Type Determination Rating usingSingle Linkage Agglomerative (Bottom-Up) Clustering Technique\n",
        "\n",
        "K_TEST = 3 # Number of clusters for the baseline k-means clustering\n",
        "ITER_KM = 20 # Number of iterations for the baseline k-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SVAFvvnDA7f"
      },
      "source": [
        "## Importing some useful (auxiliary) libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55Pl8LllzSlj"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pprint\n",
        "import networkx as nx\n",
        "from networkx.algorithms import minimum_spanning_tree\n",
        "import scipy.spatial.distance as dist\n",
        "#from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4IRnltBoOeL",
        "outputId": "adaceb52-cfdf-4d4a-c930-ed046c8873b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BZrusNGN7DWfbqqshRRbGnvXaLHsXKIP\n",
            "To: /content/seeds.csv\n",
            "\r  0% 0.00/9.53k [00:00<?, ?B/s]\r100% 9.53k/9.53k [00:00<00:00, 19.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1BZrusNGN7DWfbqqshRRbGnvXaLHsXKIP/view #seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rh7towzC434"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rV0QPynXzs2E",
        "outputId": "2ccf0aa0-837d-46ff-c1cb-c665256c18ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       A      P       C     LK     WK  A_Coef    LKG  target\n",
              "0  15.26  14.84  0.8710  5.763  3.312   2.221  5.220       0\n",
              "1  14.88  14.57  0.8811  5.554  3.333   1.018  4.956       0\n",
              "2  14.29  14.09  0.9050  5.291  3.337   2.699  4.825       0\n",
              "3  13.84  13.94  0.8955  5.324  3.379   2.259  4.805       0\n",
              "4  16.14  14.99  0.9034  5.658  3.562   1.355  5.175       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9bac333-c968-4f6c-b234-ac1ae357bad7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>P</th>\n",
              "      <th>C</th>\n",
              "      <th>LK</th>\n",
              "      <th>WK</th>\n",
              "      <th>A_Coef</th>\n",
              "      <th>LKG</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.26</td>\n",
              "      <td>14.84</td>\n",
              "      <td>0.8710</td>\n",
              "      <td>5.763</td>\n",
              "      <td>3.312</td>\n",
              "      <td>2.221</td>\n",
              "      <td>5.220</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.88</td>\n",
              "      <td>14.57</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>5.554</td>\n",
              "      <td>3.333</td>\n",
              "      <td>1.018</td>\n",
              "      <td>4.956</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.699</td>\n",
              "      <td>4.825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.84</td>\n",
              "      <td>13.94</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>5.324</td>\n",
              "      <td>3.379</td>\n",
              "      <td>2.259</td>\n",
              "      <td>4.805</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16.14</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>5.658</td>\n",
              "      <td>3.562</td>\n",
              "      <td>1.355</td>\n",
              "      <td>5.175</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9bac333-c968-4f6c-b234-ac1ae357bad7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9bac333-c968-4f6c-b234-ac1ae357bad7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9bac333-c968-4f6c-b234-ac1ae357bad7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('seeds.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEXePO4DB-FR"
      },
      "source": [
        "## Distance Metric: Cosine Similarity\n",
        "Throughout this experiment, wherever there is a notion of \"distance\" we will use cosine distance, which is $1-\\text{cosine similarity}$ where $$\\text{cosine similarity}_{u,v} = \\frac{u\\cdot v}{\\sqrt{(u\\cdot u)(v\\cdot v)}}$$ From inspection we see that cosine similarity is close to 1 for vectors that \"resemble\" each other, 0 for those unrelated (orthogonal), and -1 for those which are \"adversarial\" (antiparallel). And, it is easy to verify that cosine distance is a valid distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyGZzYJ22kD8"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(u, v):\n",
        "  return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "def distance(u, v):\n",
        "  return 1 - cosine_similarity(u, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnlITU7IDIr5"
      },
      "source": [
        "## K-means clustering\n",
        "Arguments:\n",
        "* Pandas dataframe ```df``` (input data)\n",
        "* Integer $k$ (number of clusters)\n",
        "* Integer ```num_iters``` (Number of iterations to wait for convergence\n",
        "\n",
        "Returns:\n",
        "* $k$-length np array ```cluster_means``` which are the cluster centroids\n",
        "* $k$-length list of lists ```clusters``` where each sub-list is the indices of a cluster. \n",
        "\n",
        "This method iteratively performs k-means clustering by randomly initializing centroids, clustering based on those, and updating the centroids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPfnaI-S2sGA"
      },
      "outputs": [],
      "source": [
        "def k_means(df, k=K_TEST, num_iters=ITER_KM):\n",
        "  \"\"\"\n",
        "  Method to perform k-means clustering on a pandas dataframe.\n",
        "  Args:\n",
        "  - df (Pandas dataframe, input data)\n",
        "  - k (integer, #clusters)\n",
        "  - num_iters (integer, #iterations for k-means clustering)\n",
        "  Returns:\n",
        "  - cluster_means (np.array, ith element is cluster centroids for ith cluster)\n",
        "  - clusters (list of lists, ith list is points in ith cluster)\n",
        "  \"\"\"\n",
        "  # Random initialization for cluster centroids from dataset\n",
        "  cluster_means = df.sample(k).values\n",
        "  for i in range(num_iters):\n",
        "    # Create an empty list for each cluster\n",
        "    clusters = [[] for _ in range(k)]\n",
        "    \n",
        "    # Assign each data point to the nearest cluster mean\n",
        "    for j in range(len(df)):\n",
        "      similarities = [cosine_similarity(df.iloc[j], cluster_means[l]) for l in range(k)]\n",
        "      nearest_cluster = np.argmax(similarities)\n",
        "      clusters[nearest_cluster].append(df.iloc[j])\n",
        "\n",
        "    # Update cluster means to the new centroid\n",
        "    for j in range(k):\n",
        "      cluster_means[j] = np.mean(clusters[j], axis=0)\n",
        "  \n",
        "  return cluster_means, clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYte_MuEWF0"
      },
      "source": [
        "## Some helper file I/O code\n",
        "* ```cluster_save``` writes the latest clustering for a given $k$ to a txt file where each line is a list of points in a certain cluster.\n",
        "* ```k_means_load``` loads said data to a list of sets. (For kmeans only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_KZIrFK5zq5"
      },
      "outputs": [],
      "source": [
        "def cluster_save(clusters, k = K_TEST, name='kmeans'):\n",
        "  \"\"\"\n",
        "  Method that produces a file with k lines. Each line is a comma-separated list of datapoints of a cluster.\n",
        "  Args:\n",
        "  - cluster_means (return)\n",
        "  - clusters (return)\n",
        "  - k (number of clusters)\n",
        "  \"\"\"\n",
        "\n",
        "  with open(f'{name}_{k}.txt', \"w\") as f:\n",
        "    # sorting based on least index in each cluster\n",
        "    if name == \"agglomerative\":\n",
        "      g = range(len(clusters))\n",
        "\n",
        "      for i in g:\n",
        "        cluster_data = \",\".join([str(sample) for sample in clusters[i]])  # Convert sample.name to str\n",
        "        f.write(f\"{cluster_data}\\n\")\n",
        "\n",
        "    else:\n",
        "      g = {i:x[0].name for i,x in enumerate(clusters)}\n",
        "      g = {k: v for k, v in sorted(g.items(), key=lambda item: item[1])}\n",
        "\n",
        "      for i in g:\n",
        "        cluster_data = \",\".join([str(sample.name) for sample in clusters[i]])  # Convert sample.name to str\n",
        "        f.write(f\"{cluster_data}\\n\")\n",
        "\n",
        "def k_means_load(k=K_TEST):\n",
        "    clusters = []\n",
        "    with open('kmeans_{}.txt'.format(k), 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        for row in reader:\n",
        "            data_points = [int(dp) for dp in row]\n",
        "            cluster = set(data_points)\n",
        "            clusters.append(cluster)\n",
        "\n",
        "    return clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khKfqT9yE-PJ"
      },
      "source": [
        "## Silhouette Coefficient\n",
        "We wish to evaluate our clustering. Intuitively, we want points in a cluster to be as close to each other as possible and those outside to be as far. One sufficient statistic is the silhouette coefficient-- effectively, any point in the cluster should be closer than any point in any other cluster (viz. the next closest cluster). \n",
        "\n",
        "We evaluate the clustering by the average silhouette coefficient over all points in the set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv_AXASl-7ke"
      },
      "outputs": [],
      "source": [
        "def silhouette_coefficient(df, clusters, cluster_means):\n",
        "  \"\"\"\n",
        "  Method to calculate the Silhouette Coefficient for k-means clustering.\n",
        "  Args: \n",
        "  - df (Pandas dataframe, input data)\n",
        "  - clusters (list of lists, ith list is points in ith cluster)\n",
        "  - cluster_means (np.array, ith element is cluster centroids for ith cluster)\n",
        "  Returns:\n",
        "  - Silhouette Coefficient (float)\n",
        "    - For each sample,\n",
        "      - (a-b)/max(a,b)\n",
        "      - a = The mean distance between a sample and all other points in the same cluster.\n",
        "      - b = The mean distance between a sample and all other points in the next nearest cluster.\n",
        "    - Average over all samples.\n",
        "  \"\"\"\n",
        "  n_samples = len(df)\n",
        "  n_clusters = len(clusters)\n",
        "\n",
        "  # Compute a\n",
        "  a = np.zeros(n_samples)\n",
        "  for i in range(n_clusters):\n",
        "    for sample in clusters[i]:\n",
        "      for other in clusters[i]:\n",
        "        a[sample.name] = a[sample.name] + distance(sample, other)\n",
        "  # Compute b\n",
        "  b = np.zeros(n_samples)\n",
        "  for i in range(n_clusters):\n",
        "    min = np.inf\n",
        "    min_idx = None\n",
        "    # Identify nearest cluster to the ith cluster\n",
        "    for j in range(n_clusters):\n",
        "      if j == i:\n",
        "        continue\n",
        "      if distance(cluster_means[i], cluster_means[j]) < min:\n",
        "        min = distance(cluster_means[i], cluster_means[j])\n",
        "        min_idx = j\n",
        "    for sample in clusters[i]:\n",
        "      for other in clusters[min_idx]:\n",
        "        b[sample.name] = b[sample.name] + distance(sample, other)\n",
        "\n",
        "  s = np.divide(b-a,np.maximum(b,a))\n",
        "\n",
        "  # Compute Silhouette Coefficient\n",
        "  return np.mean(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating k-means baseline\n",
        "These code cells perform k-means clustering for $k=3,4,5,6$ and writes the clustering result of each to an appropriately named file."
      ],
      "metadata": {
        "id": "4t0Sol5d1fgr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubta-g3O8LTc",
        "outputId": "505ef6fb-9325-481d-c251-a9ea6d814727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 3, s = 0.5824521339040021\n"
          ]
        }
      ],
      "source": [
        "cluster_means, clusters = k_means(df)\n",
        "cluster_save(clusters)\n",
        "s = silhouette_coefficient(df, clusters, cluster_means)\n",
        "print('k = 3, s = {}'.format(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQjc2LYRT6KD",
        "outputId": "1b1c29a9-d8c8-4454-dce1-55067694756f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 4, s = 0.5230638508698913\n",
            "k = 5, s = 0.563970047251916\n",
            "k = 6, s = 0.5421660289617972\n",
            "Greatest value of s = 0.5824521339040021 for k = 3\n"
          ]
        }
      ],
      "source": [
        "max_s = s\n",
        "best_k = 3\n",
        "for i in [4, 5, 6]:\n",
        "  cluster_means, clusters = k_means(df, k = i)\n",
        "  cluster_save(clusters, k = i)\n",
        "  s = silhouette_coefficient(df, clusters, cluster_means)\n",
        "  if s > max_s:\n",
        "    max_s = s\n",
        "    best_k = i\n",
        "  print('k = {}, s = {}'.format(i, s))\n",
        "print('Greatest value of s = {} for k = {}'.format(max_s, best_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BqrbaK0FyeJ"
      },
      "source": [
        "## Jaccard Coefficient: Similarity between sets\n",
        "We expect the clusterings to be the same no matter what we do. If they're not, we want a way to be sure they are close together. The Jaccard Coefficient or IoU does that: the intersection of points in the two sets should be large. But, that is also trivially true for a superset (say)-- it is possible the intersection may be irrelevant to one of the sets. So, we also penalize large unions.\n",
        "$$J(A,B) = \\frac{|A\\cap B|}{|A\\cup B|}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCLTY0xLWtyl"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(setA, setB):\n",
        "    intersection = setA.intersection(setB)\n",
        "    union = setA.union(setB)\n",
        "    return len(intersection) / len(union)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hnggmvMGiyH"
      },
      "source": [
        "## Representing the data as a graph (distance matrix)\n",
        "We use two methods: one is iterative (```generate_dist_matrix```) and the other (```generate_dist_matrix_2```) uses an inbuilt scipy function for comparison purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxWYJldsYfXh"
      },
      "outputs": [],
      "source": [
        "def generate_dist_matrix(df):\n",
        "  n = len(df)\n",
        "  dist_matrix = np.zeros((n,n))\n",
        "  for i in range(n):\n",
        "    for j in range(i + 1, n):\n",
        "      d = distance(df.iloc[i], df.iloc[j])\n",
        "      dist_matrix[i, j] = d\n",
        "      dist_matrix[j, i] = d  # symmetric\n",
        "  return dist_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnzypaNNeuCE"
      },
      "outputs": [],
      "source": [
        "def generate_dist_matrix_2(df):\n",
        "  return dist.squareform(dist.pdist(X=df, metric='cosine'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3vBkeRLHCLC"
      },
      "source": [
        "## Single Linkage Clustering\n",
        "We perform single linkage clustering. The basic idea is based upon our intuition for \"good\" clustering-- we try to maximize the distance between clusters by saying \"at the very least, these clusters should be $\\epsilon$ apart\" and then trying to maximize $\\epsilon$. \n",
        "### Brute Force\n",
        "We start with assigning each cluster a single point and then merging the clusters between which the minimum distance is the lowest together until we have only $k$ clusters left.\n",
        "### Kruskal's algorithm\n",
        "From the cut theorem, it is easy to verify that the distance between two clusters is the edge length between the edge connecting those clusters. So, we can also achieve the same clustering by removing the most expensive $k-1$ edges from the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4M2SJTWW2v3"
      },
      "outputs": [],
      "source": [
        "def single_linkage_clustering(dist_matrix, k):\n",
        "  n = dist_matrix.shape[0]\n",
        "\n",
        "  # Initialize each data point as a cluster\n",
        "  clusters = [{i} for i in range(n)]\n",
        "\n",
        "  while len(clusters) > k:\n",
        "    # Find the two closest clusters\n",
        "    min_dist = np.inf\n",
        "    merge_pair = None\n",
        "    for i in range(len(clusters)):\n",
        "      for j in range(i+1, len(clusters)):\n",
        "        # Find the minimum distance between the two clusters\n",
        "        dist = min([dist_matrix[p1][p2] for p1 in clusters[i] for p2 in clusters[j]])\n",
        "        if dist < min_dist:\n",
        "          min_dist = dist\n",
        "          merge_pair = (i, j)\n",
        "    # Merge the two closest clusters\n",
        "    i, j = merge_pair\n",
        "    clusters[i] = clusters[i].union(clusters[j])\n",
        "    clusters.pop(j)\n",
        "  # Return the final clusters\n",
        "  return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RwFJUjFVADG"
      },
      "outputs": [],
      "source": [
        "def single_linkage_clustering_2(dist_matrix, k):\n",
        "  n = dist_matrix.shape[0]\n",
        "  G = nx.from_numpy_array(dist_matrix)\n",
        "  mst = minimum_spanning_tree(G)\n",
        "  \n",
        "  # Sort edges by decreasing weight\n",
        "  sorted_edges = sorted(mst.edges(data=True), key=lambda x: x[2].get('weight'), reverse=True)\n",
        "  for edge in sorted_edges[:k-1]:\n",
        "    mst.remove_edge(edge[0],edge[1]) # Remove the k-1 most expensive edges\n",
        "  \n",
        "  # Return the connected components (clusters) after removing these edges\n",
        "  components = list(nx.connected_components(mst))\n",
        "  return components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj8bpsiQIrGR"
      },
      "source": [
        "## Driver code\n",
        "We take the clustering from the best $k$ and use it to perform single linkage clustering on both. We expect similar results, especially with the \"target\" label as a heuristic. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2L4G8KdaLbG",
        "outputId": "83c68f00-d89e-45d2-8a65-1d302f4668d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard scores for set-wise closest clusters in k-means and brute force:\n",
            "\t[0.5323741007194245, 0.015151515151515152, 0.9154929577464789]\n",
            "Jaccard scores for set-wise closest clusters in k-means and greedy:\n",
            "\t[0.5323741007194245, 0.015151515151515152, 0.9154929577464789]\n",
            "Jaccard scores for set-wise closest clusters in brute force and greedy:\n",
            "\t[1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# Generate the distance matrices using both methods\n",
        "dist_matrix = generate_dist_matrix(df)\n",
        "dist_matrix_2 = generate_dist_matrix_2(df)\n",
        "\n",
        "# Perform clustering\n",
        "clusters_KM = k_means_load(best_k) # Load k-means clustering for k = best_k\n",
        "clusters_AS = single_linkage_clustering(dist_matrix, k = best_k) # Perform single linkage clustering by brute force for k = best_k\n",
        "clusters_AS_2 = single_linkage_clustering_2(dist_matrix_2, best_k) # Perform single linkage clustering by Kruskal's algorithm for k = best_k\n",
        "\n",
        "# Save the agglomerative clustering results\n",
        "cluster_save(clusters_AS_2, best_k, \"agglomerative\")\n",
        "\n",
        "# Compute and report pair-wise Jaccard scores\n",
        "jaccard_scores = [[],[],[]]\n",
        "\n",
        "# Between k-means and brute force agglomerative\n",
        "for set_A in clusters_AS:\n",
        "    # Compute Jaccard similarity between set_A and each set in clusters_KM\n",
        "    scores = [jaccard_similarity(set_A, set_B) for set_B in clusters_KM]\n",
        "    # Append the maximum Jaccard similarity score to jaccard_scores\n",
        "    jaccard_scores[0].append(max(scores))\n",
        "\n",
        "# Between k-means and greedy agglomerative\n",
        "for set_A in clusters_AS_2:\n",
        "    # Compute Jaccard similarity between set_A and each set in clusters_KM\n",
        "    scores = [jaccard_similarity(set_A, set_B) for set_B in clusters_KM]\n",
        "    # Append the maximum Jaccard similarity score to jaccard_scores\n",
        "    jaccard_scores[1].append(max(scores))\n",
        "\n",
        "# Between brute force and and greedy agglomerative\n",
        "for set_A in clusters_AS_2:\n",
        "    # Compute Jaccard similarity between set_A and each set in clusters_AS\n",
        "    scores = [jaccard_similarity(set_A, set_B) for set_B in clusters_AS]\n",
        "    # Append the maximum Jaccard similarity score to jaccard_scores\n",
        "    jaccard_scores[2].append(max(scores))\n",
        "\n",
        "# Print the Jaccard similarity scores\n",
        "print('Jaccard scores for set-wise closest clusters in k-means and brute force:\\n\\t{}'.format(jaccard_scores[0]))\n",
        "print('Jaccard scores for set-wise closest clusters in k-means and greedy:\\n\\t{}'.format(jaccard_scores[1]))\n",
        "print('Jaccard scores for set-wise closest clusters in brute force and greedy:\\n\\t{}'.format(jaccard_scores[2]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}